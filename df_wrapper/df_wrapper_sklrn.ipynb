{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUJyPhS0-MrF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import requests\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import fasttext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrbJ8Tjz-Y4y"
      },
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BETPTy-f-Y7i"
      },
      "source": [
        "!gunzip --decompress cc.ru.300.bin.gz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qQkUVr6-Y9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898d6d48-1ff8-48a6-8ac8-46eab8feb3d7"
      },
      "source": [
        "model = fasttext.load_model('cc.ru.300.bin')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPAJGO8s-jth"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/dhhse/fanfics4hack/main/data/FanFics_Metadata_full.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5FNH2aT-ZDC"
      },
      "source": [
        "data = pd.read_json('FanFics_Metadata_full.json')\r\n",
        "\r\n",
        "features_columns = [\r\n",
        "       'Genre', 'Rating', 'Status', \r\n",
        "       'Title', 'Thanks', 'Author note'\r\n",
        "]\r\n",
        "\r\n",
        "data = data.dropna(subset=features_columns)\r\n",
        "data = data.drop(data.index[200:])\r\n",
        "data = data.reset_index()"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1-B6TTa-ZFh"
      },
      "source": [
        "class DFWrapper:\r\n",
        "    def __init__(self, dataframe, t_cl,\r\n",
        "                 vectorizer=CountVectorizer(), fasttext_flag=False):\r\n",
        "        # self.dataframe = dataframe.dropna() это нужно оставить в\r\n",
        "        # черновом варианте, но тестовый дф тогда будет пустым\r\n",
        "        self.dataframe = dataframe\r\n",
        "        self.dataframe = self.dataframe.reset_index()\r\n",
        "        self.t_cl = self.dataframe[[t_cl]]\r\n",
        "        self.f_cls = dataframe.drop(self.t_cl, axis=1)\r\n",
        "        self.vectorizer = vectorizer\r\n",
        "        self.fasttext_flag = fasttext_flag\r\n",
        "\r\n",
        "    @property\r\n",
        "    def features(self):\r\n",
        "        nfeatures = self.t_cl  # я честно не разобрался, как сделать\r\n",
        "# нормальный df ,у меня какая-то замара с несовместимостью df и series\r\n",
        "# результаты фичерс надо куда-то прикрепить\r\n",
        "# загружаем модель, если юзер сказал юзать fasttext\r\n",
        "        # if self.fasttext_flag:\r\n",
        "        #    model = fasttext.load_model('cc.ru.300.bin')\r\n",
        "\r\n",
        "        for column in self.f_cls:\r\n",
        "            if isinstance(self.dataframe[column][0], str):\r\n",
        "                # я проверяю по первой строке, лежат ли в столбце строки\r\n",
        "                if len(self.dataframe[column])*0.1 > \\\r\n",
        "                       self.dataframe[column].nunique():\r\n",
        "                    # я понял это так, что если в столбце значений менее\r\n",
        "                    # 10% от всей длины столбца, то тогда dummies\r\n",
        "                    dummies = pd.get_dummies(self.dataframe[column])\r\n",
        "                    nfeatures = nfeatures.join(dummies)\r\n",
        "\r\n",
        "                else:\r\n",
        "                    if self.fasttext_flag:  # если юзер хочет фасттекст\r\n",
        "                        vectorized = []\r\n",
        "                        for cell in self.dataframe[column]:\r\n",
        "                            fasttext_vector = model.get_sentence_vector(\r\n",
        "                                cell.replace('\\n', ''))\r\n",
        "                            vectorized.append(list(fasttext_vector))\r\n",
        "\r\n",
        "                    else:\r\n",
        "                        verorises = self.vectorizer.fit_transform(\r\n",
        "                            self.dataframe[column])\r\n",
        "                        vectorized = verorises.toarray()\r\n",
        "\r\n",
        "                # трансформируем данные\r\n",
        "                t = list(zip(*vectorized))\r\n",
        "                v_col = {}\r\n",
        "                n = 0\r\n",
        "                for col in t:\r\n",
        "                    v_col['vec_{}_{}'.format(column, n)] = col\r\n",
        "                    n += 1\r\n",
        "\r\n",
        "                nfeatures = nfeatures.join(pd.DataFrame(v_col))\r\n",
        "\r\n",
        "        return nfeatures.drop(self.t_cl, axis=1)\r\n",
        "\r\n",
        "    def fit(self, clas):\r\n",
        "        f_features = self.features  # не хочу изменять аттрибут\r\n",
        "        f_dataframe = f_features.join(self.t_cl)\r\n",
        "        data_train, data_test = train_test_split(f_dataframe)\r\n",
        "        if isinstance(clas, type(KNeighborsClassifier())) or \\\r\n",
        "           isinstance(clas, type(LogisticRegression())):\r\n",
        "            neight = clas.fit(X=data_train[list(self.features.columns)],\r\n",
        "                              y=data_train[list(self.t_cl.columns)[0]])\r\n",
        "\r\n",
        "        return model\r\n",
        "\r\n",
        "\r\n",
        "df = DFWrapper(data, 'Genre',  vectorizer=False, fasttext_flag=True)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Fp_pJS-n7N"
      },
      "source": [
        "z = df.features"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-RRD7S1X-yL",
        "outputId": "c66e69f2-d7d1-43a7-8632-dfc78fbbb46a"
      },
      "source": [
        "df.fit(KNeighborsClassifier())"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fasttext.FastText._FastText at 0x7fec4ccbd0d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyYWIIhMX-0n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}