{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_6__Gensim_TopicModeling_Gensim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGMHzNQQEm-u"
      },
      "source": [
        "Сейчас будет много копипаста с тетрадки семинара)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcpF3Fn79bqY"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONW1vJ919hEJ"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpIsCv5m9_A6"
      },
      "source": [
        "!pip  install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Filfs7op8WkY"
      },
      "source": [
        "import nltk; nltk.download('stopwords')\n",
        "\n",
        "!python3 -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsxRoSGK9zBL"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYWmtv1M91nu"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAyh7LTgAVch",
        "outputId": "80584cc1-8e14-43e8-ba7f-080a4cd83367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(df.target_names.unique())\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFYYdWG4BPQ1"
      },
      "source": [
        "Чистка даты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_DJRWg8BGsW",
        "outputId": "d1d5b286-9d4d-4f46-a0bb-69b1d31011e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Convert to list\n",
        "data = df.content.values.tolist()\n",
        "\n",
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "pprint(data[:1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
            " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
            " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
            " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
            " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
            " 'addition, the front bumper was separate from the rest of the body. This is '\n",
            " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
            " 'production, where this car is made, history, or whatever info you have on '\n",
            " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
            " 'your neighborhood Lerxst ---- ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4tBFnlBa_v",
        "outputId": "f7a41271-bc1a-4c79-db90-f3c1c84f0cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#tokenize\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TfuXp2FBHG"
      },
      "source": [
        "программа, которая нам руками будет возвращать N-число самых частых биграмм в тексте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGTWQtPCCjo_"
      },
      "source": [
        "bigrams = [b for l in data_words for b in zip(l[:-1], l[1:])]\n",
        "freq = nltk.FreqDist(bigrams) #computes freq of occurrence\n",
        "fdist = freq.keys() # sorted according to freq"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqxJzKq5B07B",
        "outputId": "9d1a61ba-c79a-4bee-d2d9-f4eb25fbd5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLY1GmA0BbmB"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE1F6oMECSvm",
        "outputId": "f56c08c7-2d9e-4121-c3bd-ca9e5f2e15e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['where', 'thing', 'car', 'nntp_poste', 'host', 'park', 'line', 'wonder', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'separate', 'rest', 'body', 'know', 'tellme', 'model', 'name', 'engine', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Wa02IHC59A",
        "outputId": "e0787f1b-3cda-4bdc-c0f4-5857d76083d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 5), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC81CRa8F4Dw"
      },
      "source": [
        "Mallen, который смог. Будь как маллет."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROQqpEFfCd8y"
      },
      "source": [
        "!unzip /content/mallet-2.0.8.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EKcaw__DStc",
        "outputId": "1c5e5094-1770-4579-d69c-514f32b8ed64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "mallet_path = '/content/mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEYmWpOREaDS",
        "outputId": "5e731050-90fe-4e80-f436-f74f31753f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Show Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2,\n",
            "  [('ax', 0.1955242436800663),\n",
            "   ('line', 0.16730211355159552),\n",
            "   ('max', 0.157563199336925),\n",
            "   ('host', 0.09270617488603398),\n",
            "   ('nntp_poste', 0.03825113966017406),\n",
            "   ('ca', 0.01910484873601326),\n",
            "   ('organization', 0.014007459593866557),\n",
            "   ('reply', 0.012681309573145462),\n",
            "   ('distribution_usa', 0.01226688769167012),\n",
            "   ('keyword', 0.009863240779113137)]),\n",
            " (9,\n",
            "  [('key', 0.03811417331161827),\n",
            "   ('system', 0.016011336957211447),\n",
            "   ('encryption', 0.014086592356014298),\n",
            "   ('technology', 0.012309905031832314),\n",
            "   ('bit', 0.012077243596522768),\n",
            "   ('chip', 0.011950337359081199),\n",
            "   ('information', 0.011759978002918843),\n",
            "   ('message', 0.011675373844624463),\n",
            "   ('security', 0.009602571966412149),\n",
            "   ('public', 0.009602571966412149)]),\n",
            " (8,\n",
            "  [('thing', 0.038082857899424664),\n",
            "   ('make', 0.0339905153944296),\n",
            "   ('time', 0.027105750944849665),\n",
            "   ('bad', 0.025131797501263813),\n",
            "   ('back', 0.02308562624876628),\n",
            "   ('happen', 0.018680339905153946),\n",
            "   ('lot', 0.018415541272477794),\n",
            "   ('good', 0.016224934402156905),\n",
            "   ('hear', 0.016224934402156905),\n",
            "   ('remember', 0.016152716593245228)]),\n",
            " (19,\n",
            "  [('game', 0.03435617266622039),\n",
            "   ('year', 0.03228314150597076),\n",
            "   ('team', 0.029389535511455657),\n",
            "   ('play', 0.026236800621909348),\n",
            "   ('player', 0.020320024185363536),\n",
            "   ('win', 0.018873221188105985),\n",
            "   ('good', 0.014165712928372454),\n",
            "   ('season', 0.012502969185255565),\n",
            "   ('run', 0.011380077306787018),\n",
            "   ('fan', 0.009695739489084195)]),\n",
            " (0,\n",
            "  [('people', 0.030135273896156077),\n",
            "   ('make', 0.02841644716281977),\n",
            "   ('pay', 0.01821509888834323),\n",
            "   ('money', 0.01810348676280191),\n",
            "   ('work', 0.015982856377516855),\n",
            "   ('year', 0.014978347247644984),\n",
            "   ('government', 0.014710478146345818),\n",
            "   ('job', 0.013371132639849993),\n",
            "   ('give', 0.010603151926425287),\n",
            "   ('talk', 0.009509353096120363)]),\n",
            " (6,\n",
            "  [('good', 0.058377576888123596),\n",
            "   ('time', 0.05304443487827044),\n",
            "   ('problem', 0.04584588893671976),\n",
            "   ('question', 0.03709283971875448),\n",
            "   ('find', 0.03522743578705697),\n",
            "   ('work', 0.03319462381020711),\n",
            "   ('make', 0.021739130434782608),\n",
            "   ('change', 0.02094992107906443),\n",
            "   ('thing', 0.020591189553737982),\n",
            "   ('give', 0.019586741282823936)]),\n",
            " (4,\n",
            "  [('study', 0.011241007194244604),\n",
            "   ('effect', 0.009592326139088728),\n",
            "   ('food', 0.008967825739408472),\n",
            "   ('test', 0.00876798561151079),\n",
            "   ('doctor', 0.008268385291766586),\n",
            "   ('eat', 0.007643884892086331),\n",
            "   ('patient', 0.0073441247002398085),\n",
            "   ('day', 0.006669664268585132),\n",
            "   ('problem', 0.00649480415667466),\n",
            "   ('report', 0.00644484412470024)]),\n",
            " (17,\n",
            "  [('people', 0.014484123172676106),\n",
            "   ('word', 0.012409474230170775),\n",
            "   ('love', 0.011545037170793554),\n",
            "   ('religion', 0.010430873849818468),\n",
            "   ('christian', 0.010315615575234839),\n",
            "   ('church', 0.009720114489886087),\n",
            "   ('man', 0.009124613404537334),\n",
            "   ('life', 0.008413854044604952),\n",
            "   ('book', 0.007799143246825595),\n",
            "   ('day', 0.00770309468467257)]),\n",
            " (3,\n",
            "  [('file', 0.03684842936430738),\n",
            "   ('program', 0.021356640155633117),\n",
            "   ('window', 0.016707672941580362),\n",
            "   ('image', 0.014361732562796818),\n",
            "   ('version', 0.012688104365737828),\n",
            "   ('server', 0.011057389712193168),\n",
            "   ('set', 0.010628254277049836),\n",
            "   ('display', 0.010370773015963838),\n",
            "   ('application', 0.009913028551810952),\n",
            "   ('include', 0.008782971905933513)]),\n",
            " (5,\n",
            "  [('government', 0.014099216710182768),\n",
            "   ('people', 0.012783289817232375),\n",
            "   ('state', 0.011342036553524804),\n",
            "   ('israeli', 0.010819843342036553),\n",
            "   ('war', 0.010255874673629243),\n",
            "   ('attack', 0.009733681462140991),\n",
            "   ('turkish', 0.009065274151436032),\n",
            "   ('force', 0.008960835509138381),\n",
            "   ('world', 0.008793733681462142),\n",
            "   ('country', 0.00856396866840731)])]\n",
            "\n",
            "Coherence Score:  0.5517165443441068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7PuV3-_DWwI"
      },
      "source": [
        "Первая цифра - айди слова в документе, вторая - частота этого слова в документе.\n",
        "таков формат ввода"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-35v67xD1gG",
        "outputId": "6f48040c-9653-4b92-9df9-e05f99fe784f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('addition', 1),\n",
              "  ('body', 1),\n",
              "  ('bricklin', 1),\n",
              "  ('bring', 1),\n",
              "  ('call', 1),\n",
              "  ('car', 5),\n",
              "  ('could', 1),\n",
              "  ('day', 1),\n",
              "  ('door', 2),\n",
              "  ('early', 1),\n",
              "  ('engine', 1),\n",
              "  ('enlighten', 1),\n",
              "  ('funky', 1),\n",
              "  ('history', 1),\n",
              "  ('host', 1),\n",
              "  ('info', 1),\n",
              "  ('know', 1),\n",
              "  ('late', 1),\n",
              "  ('lerxst', 1),\n",
              "  ('line', 1),\n",
              "  ('look', 2),\n",
              "  ('mail', 1),\n",
              "  ('make', 1),\n",
              "  ('model', 1),\n",
              "  ('name', 1),\n",
              "  ('neighborhood', 1),\n",
              "  ('nntp_poste', 1),\n",
              "  ('park', 1),\n",
              "  ('production', 1),\n",
              "  ('really', 1),\n",
              "  ('rest', 1),\n",
              "  ('see', 1),\n",
              "  ('separate', 1),\n",
              "  ('small', 1),\n",
              "  ('sport', 1),\n",
              "  ('tellme', 1),\n",
              "  ('thank', 1),\n",
              "  ('thing', 1),\n",
              "  ('where', 1),\n",
              "  ('wonder', 1),\n",
              "  ('year', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhwy16jWD9-6"
      },
      "source": [
        "## Тренеруем нашу модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBmqT7oLD9YP"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70i5r5TFD6M5",
        "outputId": "2165a7f0-359f-4ae4-d64b-e13e32a56140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]\n",
        "#показывает не все слова, а 10 первых"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.051*\"report\" + 0.027*\"black\" + 0.020*\"fire\" + 0.020*\"white\" + '\n",
            "  '0.016*\"trial\" + 0.016*\"cover\" + 0.015*\"medium\" + 0.013*\"vote\" + '\n",
            "  '0.012*\"minor\" + 0.012*\"title\"'),\n",
            " (1,\n",
            "  '0.021*\"god\" + 0.020*\"accept\" + 0.016*\"member\" + 0.015*\"man\" + '\n",
            "  '0.014*\"israeli\" + 0.014*\"season\" + 0.012*\"publish\" + 0.012*\"lebanese\" + '\n",
            "  '0.012*\"jewish\" + 0.011*\"brain\"'),\n",
            " (2,\n",
            "  '0.017*\"package\" + 0.016*\"press\" + 0.015*\"item\" + 0.015*\"break\" + '\n",
            "  '0.011*\"level\" + 0.010*\"edge\" + 0.009*\"hole\" + 0.007*\"eye\" + '\n",
            "  '0.007*\"equipment\" + 0.007*\"contribute\"'),\n",
            " (3,\n",
            "  '0.025*\"pc\" + 0.022*\"contain\" + 0.020*\"input\" + 0.020*\"reality\" + '\n",
            "  '0.017*\"picture\" + 0.016*\"object\" + 0.016*\"level\" + 0.015*\"box\" + '\n",
            "  '0.015*\"quality\" + 0.013*\"greek\"'),\n",
            " (4,\n",
            "  '0.089*\"ax\" + 0.076*\"max\" + 0.032*\"space\" + 0.021*\"launch\" + 0.018*\"di_di\" + '\n",
            "  '0.017*\"orbit\" + 0.016*\"sphere\" + 0.015*\"satellite\" + 0.014*\"plane\" + '\n",
            "  '0.014*\"mission\"'),\n",
            " (5,\n",
            "  '0.019*\"people\" + 0.017*\"kill\" + 0.015*\"child\" + 0.015*\"government\" + '\n",
            "  '0.012*\"attack\" + 0.012*\"year\" + 0.012*\"die\" + 0.011*\"country\" + 0.010*\"say\" '\n",
            "  '+ 0.009*\"war\"'),\n",
            " (6,\n",
            "  '0.035*\"window\" + 0.032*\"card\" + 0.020*\"image\" + 0.020*\"driver\" + '\n",
            "  '0.020*\"problem\" + 0.019*\"run\" + 0.018*\"sale\" + 0.018*\"machine\" + '\n",
            "  '0.017*\"color\" + 0.016*\"screen\"'),\n",
            " (7,\n",
            "  '0.025*\"people\" + 0.021*\"say\" + 0.014*\"reason\" + 0.014*\"believe\" + '\n",
            "  '0.012*\"may\" + 0.012*\"evidence\" + 0.010*\"make\" + 0.010*\"think\" + '\n",
            "  '0.009*\"many\" + 0.009*\"mean\"'),\n",
            " (8,\n",
            "  '0.032*\"book\" + 0.023*\"physical\" + 0.021*\"science\" + 0.017*\"choose\" + '\n",
            "  '0.016*\"explain\" + 0.015*\"create\" + 0.011*\"author\" + 0.011*\"earth\" + '\n",
            "  '0.010*\"study\" + 0.010*\"nature\"'),\n",
            " (9,\n",
            "  '0.033*\"mail\" + 0.028*\"file\" + 0.027*\"send\" + 0.026*\"program\" + '\n",
            "  '0.025*\"thank\" + 0.024*\"information\" + 0.021*\"software\" + 0.021*\"list\" + '\n",
            "  '0.019*\"include\" + 0.019*\"address\"'),\n",
            " (10,\n",
            "  '0.073*\"group\" + 0.031*\"week\" + 0.021*\"young\" + 0.017*\"drug\" + 0.015*\"watch\" '\n",
            "  '+ 0.013*\"nntp_posting\" + 0.013*\"age\" + 0.013*\"route\" + 0.011*\"kid\" + '\n",
            "  '0.010*\"capable\"'),\n",
            " (11,\n",
            "  '0.073*\"car\" + 0.023*\"existence\" + 0.022*\"model\" + 0.020*\"engine\" + '\n",
            "  '0.016*\"pain\" + 0.012*\"keyboard\" + 0.012*\"mile\" + 0.011*\"should\" + '\n",
            "  '0.011*\"price\" + 0.011*\"insurance\"'),\n",
            " (12,\n",
            "  '0.070*\"drive\" + 0.025*\"power\" + 0.024*\"player\" + 0.017*\"speed\" + '\n",
            "  '0.017*\"light\" + 0.014*\"high\" + 0.013*\"bus\" + 0.012*\"university\" + '\n",
            "  '0.012*\"fast\" + 0.012*\"scsi\"'),\n",
            " (13,\n",
            "  '0.040*\"line\" + 0.039*\"would\" + 0.035*\"write\" + 0.024*\"article\" + 0.021*\"be\" '\n",
            "  '+ 0.020*\"get\" + 0.020*\"know\" + 0.020*\"go\" + 0.014*\"good\" + 0.014*\"think\"'),\n",
            " (14,\n",
            "  '0.027*\"patient\" + 0.017*\"family\" + 0.014*\"food\" + 0.013*\"treatment\" + '\n",
            "  '0.012*\"disease\" + 0.012*\"doctor\" + 0.011*\"cd\" + 0.011*\"diagnosis\" + '\n",
            "  '0.011*\"risk\" + 0.010*\"cause\"'),\n",
            " (15,\n",
            "  '0.029*\"wire\" + 0.021*\"ground\" + 0.021*\"eat\" + 0.019*\"material\" + '\n",
            "  '0.018*\"seller\" + 0.018*\"controller\" + 0.016*\"signal\" + 0.016*\"trust\" + '\n",
            "  '0.015*\"lead\" + 0.015*\"expensive\"'),\n",
            " (16,\n",
            "  '0.042*\"gun\" + 0.025*\"right\" + 0.016*\"carry\" + 0.015*\"law\" + 0.014*\"state\" + '\n",
            "  '0.014*\"crime\" + 0.014*\"weapon\" + 0.014*\"shoot\" + 0.013*\"steal\" + '\n",
            "  '0.013*\"protect\"'),\n",
            " (17,\n",
            "  '0.028*\"use\" + 0.025*\"system\" + 0.016*\"also\" + 0.014*\"may\" + 0.014*\"number\" '\n",
            "  '+ 0.012*\"new\" + 0.009*\"work\" + 0.009*\"support\" + 0.008*\"bit\" + '\n",
            "  '0.008*\"need\"'),\n",
            " (18,\n",
            "  '0.043*\"team\" + 0.039*\"game\" + 0.036*\"year\" + 0.030*\"play\" + 0.024*\"win\" + '\n",
            "  '0.017*\"lose\" + 0.013*\"hit\" + 0.013*\"fan\" + 0.012*\"last\" + 0.012*\"hockey\"'),\n",
            " (19,\n",
            "  '0.054*\"key\" + 0.030*\"public\" + 0.021*\"government\" + 0.017*\"internet\" + '\n",
            "  '0.015*\"encryption\" + 0.015*\"technology\" + 0.014*\"chip\" + 0.014*\"security\" + '\n",
            "  '0.014*\"instal\" + 0.013*\"private\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ly8JIifGJVM"
      },
      "source": [
        "Расскажу про Coherence score - результат оценки тематических моделей (то есть таких моделей, которые определяют темы документов). Чем ближе к 1 значение, тем более связанные получились темы. Определяется косинусным сходством."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMJm4yc4H15W"
      },
      "source": [
        "Дальше пока ничего нет, можно не читать))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ76RdQaHGxr"
      },
      "source": [
        "## Как нам понять, что наша модель хороша?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPe1vij8HPdx"
      },
      "source": [
        "Во-первых, можно использовать perplexity. Помните, что наша модель (1) и (2) основанная на теориях вероятности? Значит, можно использовать perplexity. In information theory, perplexity is a measurement of how well a probability distribution or probability model predicts a sample. It may be used to compare probability models. A low perplexity indicates the probability distribution is good at predicting the sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RltBn_fiH5N4"
      },
      "source": [
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL1zW7m9IacN"
      },
      "source": [
        "Также можно посчитать - другую штуку --- coherence score, придуманную одним индийским мальчиком. Люди пишут, что она лучше работает https://rare-technologies.com/what-is-topic-coherence/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsvKbnffJEBB"
      },
      "source": [
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_OitGpAIA9x"
      },
      "source": [
        "Также можно поработать головой самим.\n",
        "Заметьте, что тут нумерация начинается с 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aXeFjA5F7xc"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5v57CZHB1d"
      },
      "source": [
        "Полазать по 1-3 и 16 посмотреть, что к чему"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cQAZkRuJgUl"
      },
      "source": [
        "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n",
        "\n",
        "We have successfully built a good looking topic model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X_cAXG3JjCB"
      },
      "source": [
        "Поэксперементируем с фича инженирингом и найдём модель получше?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soHklk4ZMch6"
      },
      "source": [
        "перейдём к дз"
      ]
    }
  ]
}
