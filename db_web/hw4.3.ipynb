{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Арцишевский Антон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('otaku_news.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS texts \n",
    "(id int PRIMARY KEY, date int, title text, category text)\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS add_info\n",
    "(id int PRIMARY KEY, tag_name text, likes int) \n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS text_to_add_info\n",
    "(id INTEGER PRIMARY KEY AUTOINCREMENT, id_text int, id_tag int) \n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробую сначала по-порядку всё сделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1\n",
    "url = f'https://otakumode.com/news/anime?page={page_number}.html'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guide on Donating to Kyoto Animation'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = soup.find_all('h3', {'class': 'p-article__title'})\n",
    "title = news[0].find('a').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['inherit'],\n",
       " 'href': '/news/5d4000fdad221889188b9e55/Guide-on-Donating-to-Kyoto-Animation',\n",
       " 'onclick': \"tom.helper.ga.push(['event', 'News', 'Clicked', 'CategoryFeatured_5d4000fdad221889188b9e55', 1]);\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs = news[0].find('a').attrs\n",
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/news/5d4000fdad221889188b9e55/Guide-on-Donating-to-Kyoto-Animation'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = news[0].find('a').attrs['href']\n",
    "href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаю ссылку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://otakumode.com/news/5d4000fdad221889188b9e55/Guide-on-Donating-to-Kyoto-Animation'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_one = 'https://otakumode.com'+href\n",
    "url_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = session.get(url_one, headers={'User-Agent': ua.random})\n",
    "page = req.text\n",
    "\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ТЕКСТ СТАТЬИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Renowned anime studio Kyoto Animation suffered an arson attack on July 18th, 2019 (JST), which took over 30 lives and injured more. As the studio behind countless beloved anime like K-ON!, The Melancholy of Suzumiya Haruhi and Hibike! Euphonium, Kyoto Animation has received an outpouring of love from fans all around the world. Those who wish to support their recovery can do so by donating through the official channels below.*The information in this article is accurate as of August 1st, 2019. For future updates please check Kyoto Animation’s official website.”  Donating directly to Kyoto AnimationBANK NAME : THE KYOTO SHINKIN BANKSWIFT : KYSBJPJZBRANCH NAME : MINAMI MOMOYAMA BRANCHBRANCH NUMBER : 048ADDRESS : 16-50, YOSAI, MOMOYAMA-CHO, HUSHIMI-KU, KYOTO-SHI, KYOTO-HU, 612-8016 , JAPANACCOUNT NUMBER : 0002890ACCOUNT HOLDER : KYOTO ANIMATION CO.,LTD., REPRESENTATIVE DIRECTOR, HATTA HIDEAKI Donating through the Association of Japanese AnimatorsBANK NAME : MUFG Bank, LTD.SWIFT : BOTKJPJTBRANCH NAME : AKIHABARA BRANCHBRANCH NUMBER : 626ACCOUNT NUMBER : 3120091BANK ADDRESS : 3-16-8, Sotokanda, Chiyoda-ku, Tokyo, JapanACCOUNT NAME : NIHON DOUGA KYOKAI KYO-ANI GIENKINACCOUNT HOLDER’S ADDRESS : Momose Bldg, 2F, 1-7-2, Kanda-izumicho,Chiyoda-ku, Tokyo 101-0024, Japan Donating through Sentai Filmworks' fundraiserSentai Filmworks' GoFundMe pageAlthough it's sure to take time, we at TOM, along with millions of other fans, wish the best for Kyoto Animation's recovery and future projects. Those in Japan can head to cinemas from September 6 to catch their newest release, Violet Evergarden Gaiden - Eternity and the Auto Memory Doll, which was originally slated for a two-week run, but has now been extended to three weeks.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = soup.find_all('div', {'class': 'p-article__text'})\n",
    "text = []\n",
    "for i in full_text:\n",
    "    i = str(i)\n",
    "    paragraph = re.findall(r'<p>(.+?)</p>', i)\n",
    "    paragraph = paragraph[0]\n",
    "    paragraph = re.sub(r'<.*?>', '', paragraph)\n",
    "    text.append(paragraph)\n",
    "all_paragraphs = ''\n",
    "for i in text:\n",
    "    all_paragraphs += i\n",
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anime']\n"
     ]
    }
   ],
   "source": [
    "meta = soup.find('a', {'class': 'c-btn c-btn--sm c-btn--icon-left c-btn--tag'})\n",
    "meta = str(meta)\n",
    "\n",
    "tags = re.findall(r'</i>(.*?)</a>', meta)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь по функциям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "    value: key+1\n",
    "    for key, value in enumerate(\n",
    "        ['янв', 'фев', 'мар', 'апр', 'мая', 'июн', 'июл', 'авг', 'сен', 'окт', 'ноя', 'дек']\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "page_number = n\n",
    "url = f'https://otakumode.com/news/anime?page={page_number}.html'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "news = soup.find_all('h3', {'class': 'p-article__title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_first_level_info(one_block):\n",
    "    block = {}\n",
    "    block['title'] = one_block.find('a').text\n",
    "    block['href'] = one_block.find('a').attrs['href']\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_second_level_info(block):\n",
    "    url_one = 'https://otakumode.com' + block['href']\n",
    "    req = session.get(url_one, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    dates = soup.find('time', {'class': 'p-article__time'})\n",
    "    dates = str(dates)\n",
    "    dates = re.search('00\">(.+?)</time>', page)\n",
    "    block['date'] = dates.group(1)\n",
    "    \n",
    "    full_text = soup.find_all('div', {'class': 'p-article__text'})\n",
    "    text = []\n",
    "    for i in full_text:\n",
    "        i = str(i)\n",
    "        paragraph = re.findall(r'<p>(.+?)</p>', i)\n",
    "        paragraph = paragraph[0]\n",
    "        paragraph = re.sub(r'<.*?>', '', paragraph)\n",
    "        text.append(paragraph)\n",
    "    all_paragraphs = ''\n",
    "    for i in text:\n",
    "        all_paragraphs += i\n",
    "    block['full_text'] = all_paragraphs\n",
    "    \n",
    "    meta = soup.find_all('a', {'class': 'c-btn c-btn--sm c-btn--icon-left c-btn--tag'})\n",
    "    meta = str(meta)\n",
    "    tags = re.findall(r'</i>(.*?)</a>', meta)\n",
    "    block['tags'] = tags\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_page(page_number):\n",
    "    url = f'https://otakumode.com/news/anime?page={page_number}.html'\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    news = soup.find_all('h3', {'class': 'p-article__title'})\n",
    "    blocks = []\n",
    "    for n in news:\n",
    "        try:\n",
    "            blocks.append(parse_first_level_info(n))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    result = []\n",
    "    for b in blocks:\n",
    "        result.append(b['href'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Не работает\n",
    "def write_to_db(block):\n",
    "    tags = []\n",
    "    for tag in block['tags']:\n",
    "        if tag in db_tags:\n",
    "            tags.append(db_tags[tag])\n",
    "        else:\n",
    "            db_tags[tag] = len(db_tags) + 1 \n",
    "            cur.execute('INSERT INTO add_info VALUES (?, ?)', (len(db_add_info), tag))\n",
    "            conn.commit()\n",
    "            tags.append(db_tags[tag])\n",
    "    text_id = len(seen_news) + 1\n",
    "    cur.execute(\n",
    "        'INSERT INTO texts VALUES (?, ?, ?, ?)',\n",
    "        (text_id,\n",
    "         block['date'],\n",
    "         block['title'], block['full_text'])\n",
    "    )\n",
    "    tags = [(text_id, t) for t in tags]\n",
    "    cur.executemany(\n",
    "        'INSERT INTO text_to_add_info (id_text, id_tag) VALUES (?, ?)',\n",
    "        tags\n",
    "    )\n",
    "    conn.commit()\n",
    "    seen_news.add(block['otaku_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инфа с первой страницы со статьями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('otaku_news.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT tag_name, id FROM add_info')\n",
    "\n",
    "db_tags = {}\n",
    "for name, idx in cur.fetchall():\n",
    "    print(name, idx)\n",
    "    db_tags[name] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "page_number = n\n",
    "url = f'https://otakumode.com/news/anime?page={page_number}.html'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "news = soup.find_all('h3', {'class': 'p-article__title'})\n",
    "\n",
    "for block in news:\n",
    "    blog1 = parse_first_level_info(block)\n",
    "    titlelinktexttag = parse_second_level_info(blog1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну я выкачал информацию про все статьи и внутреннию их информацию с первой страницы сайта. Остальные страницы я не сделал и в дб не запихнул"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
