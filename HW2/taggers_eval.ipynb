{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OYXqkYe4SLC1"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UFQXqNLj6-2"
   },
   "source": [
    "ТЕКСТЫ. Сложность в омоформах, названиях и именях похожих на сущ. и тд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "FbexhwIOSLC5"
   },
   "outputs": [],
   "source": [
    "text1 = \"\"\"Сидя в баре на Маросейке, Виноградова пила джин и ела макарон.\n",
    "Я вошёл в землянку, кругом лежали пилы и плюшки.\n",
    "Я надел наушники на уши, шапку на голову и повесил лестницу.\n",
    "Моя мама была ученым физиком, но тем не менее она хорошо готовила супы и закуски.\n",
    "Уличный шум стих, Петя пришёл домой и лёг на печь.\n",
    "Вода стекла по трубе, поэтому в доме больше не осталось стекла.\n",
    "Три тёрку и тогда сможешь приготовить мой вкусный осенний суп.\n",
    "Вертел я этот СОП на большом вертеле, его придумали серобуромалиновые черти.\n",
    "Я лечу к моей возлюбленной, потому что окрылен крыльями любви и программирования.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2clRI8AScwTh"
   },
   "outputs": [],
   "source": [
    "gold1 = ['VERB', 'PREP', 'NOUN', 'PREP', 'NOUN', 'PROPN', 'VERB', 'NOUN', 'CONJ', 'VERB', 'NOUN',\n",
    "         'PRON', 'VERB', 'PREP', 'NOUN', 'ADV', 'VERB', 'NOUN', 'CONJ', 'NOUN',\n",
    "         'PRON', 'VERB', 'NOUN', 'PREP', 'NOUN', 'NOUN', 'PREP', 'NOUN', 'CONJ', 'VERB', 'NOUN',\n",
    "         'PRON', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'CONJ', 'PRON', 'PART', 'ADV', 'PRON', 'ADV', 'VERB', 'NOUN', 'CONJ', 'NOUN',\n",
    "         'ADJ', 'NOUN', 'VERB', 'PROPN', 'VERB', 'NOUN', 'CONJ', 'VERB', 'PREP', 'NOUN',\n",
    "         'NOUN', 'VERB', 'PREP', 'NOUN', 'CONJ', 'PREP', 'NOUN', 'ADV', 'PART', 'VERB', 'NOUN',\n",
    "         'VERB', 'NOUN', 'CONJ', 'ADV', 'VERB', 'VERB', 'PRON', 'ADJ', 'ADJ', 'NOUN',\n",
    "         'VERB', 'PRON', 'PRON', 'NOUN', 'PREP', 'ADJ', 'NOUN', 'PRON', 'VERB', 'ADJ', 'NOUN',\n",
    "         'PRON', 'VERB', 'PREP', 'PRON', 'NOUN', 'CONJ', 'CONJ', 'VERB', 'NOUN', 'NOUN', 'CONJ', 'NOUN'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vkji16O3SLC9"
   },
   "outputs": [],
   "source": [
    "text2 = \"\"\"The black moon rose from behind the blind mountains.\n",
    "Johnson fired the match.\n",
    "A close look to the import informed us that the lead was broken.\n",
    "The object was refused because of his wound.\n",
    "The town authorities found money for the recreation of an ancient church.\n",
    "He decided to go to a resort for recreation.\n",
    "I will present him with this book.\n",
    "Her room is minute. There is a bed only. \n",
    "Your access is invalid.\n",
    "The diagram shows us a sharp increase in sales.\n",
    "He spoke with a grave tone which sounded weird.\n",
    "We sent four delegates to the conference. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "tag7G9J6cy_n"
   },
   "outputs": [],
   "source": [
    "gold2 = ['DET', 'ADJ', 'NOUN', 'VERB', 'ADP', 'ADP', 'DET', 'ADJ', 'NOUN',\n",
    "         'PROPN', 'VERB', 'DET', 'NOUN',\n",
    "         'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'PRON', 'SCONJ', 'DET', 'NOUN', 'AUX', 'VERB',\n",
    "         'DET', 'NOUN', 'AUX', 'VERB', 'SCONJ', 'ADP', 'PRON', 'NOUN',\n",
    "         'DET', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN',\n",
    "         'PRON', 'VERB', 'PART', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN',\n",
    "         'PRON', 'AUX', 'VERB', 'PRON', 'ADP', 'DET', 'NOUN',\n",
    "         'PRON', 'NOUN', 'VERB', 'ADJ', 'PRON', 'VERB', 'DET', 'NOUN', 'ADV',\n",
    "         'DET', 'NOUN', 'VERB', 'ADJ',\n",
    "         'DET', 'NOUN', 'VERB', 'PRON', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN',\n",
    "         'PRON', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRON', 'VERB', 'ADJ',\n",
    "         'PRON', 'VERB', 'NUM', 'NOUN', 'ADP', 'DET', 'NOUN'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2hlS_y21nv3"
   },
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "id": "3sFBINEQ2J8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\trekc\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (8.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "id": "2vDgI2ja2Uix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-sm==3.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl#egg=en_core_web_sm==3.1.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.50.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "-jmYrv5G2ocV"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_eng = []\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text2)\n",
    "\n",
    "for i, s in enumerate(doc.sents):\n",
    "    for t in s:\n",
    "      if t.pos_ != 'SPACE' and t.pos_ != 'PUNCT':\n",
    "        spacy_eng.append(t.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYxx70o1SLDA"
   },
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "id": "mY2gBm_HSLDA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trekc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "qfWZTGKxSLDE"
   },
   "outputs": [],
   "source": [
    "tokens = [w.lower() for w in word_tokenize(text2) if w.isalpha()]\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "nltk_eng = []\n",
    "for word, tag in tagged:\n",
    "    nltk_eng.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2DCwNThSLDG"
   },
   "source": [
    "### FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "id": "XEH9BMh3HyNu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in c:\\users\\trekc\\anaconda3\\lib\\site-packages (0.8.0.post1)\n",
      "Requirement already satisfied: torch<=1.7.1,>=1.5.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.7.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (4.6.1)\n",
      "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (3.8.3)\n",
      "Requirement already satisfied: janome in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.0.13)\n",
      "Requirement already satisfied: regex in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (2020.10.15)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (4.6.5)\n",
      "Requirement already satisfied: ftfy in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (6.0.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.1.95)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.23.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.8.9)\n",
      "Requirement already satisfied: langdetect in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (3.3.2)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.5.10)\n",
      "Requirement already satisfied: numpy<1.20.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.19.2)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (1.2.12)\n",
      "Requirement already satisfied: gdown==3.12.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (3.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: transformers>=4.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (4.8.2)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (4.50.2)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.2.5)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from flair) (0.3.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.15.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair) (0.29.14)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.5.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from huggingface-hub->flair) (21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from huggingface-hub->flair) (2.24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from huggingface-hub->flair) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (5.3.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (0.0.45)\n",
      "Requirement already satisfied: future in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.6.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->flair) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->flair) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from requests->huggingface-hub->flair) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt>=0.1.1->flair) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Hd3WazwcSLDI"
   },
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "hzDkaB6ISLDG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-15 12:14:10,394 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2021-07-15 12:14:10,396 --------------------------------------------------------------------------------\n",
      "2021-07-15 12:14:10,397 The model key 'upos' now maps to 'https://huggingface.co/flair/upos-english' on the HuggingFace ModelHub\n",
      "2021-07-15 12:14:10,397  - The most current version of the model is automatically downloaded from there.\n",
      "2021-07-15 12:14:10,398  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/upos/en-pos-ontonotes-v0.4.pt)\n",
      "2021-07-15 12:14:10,398 --------------------------------------------------------------------------------\n",
      "2021-07-15 12:14:10,987 loading file C:\\Users\\trekc\\.flair\\models\\upos-english\\3489359470b8c3b3c6419514a5f1e27ee827089d6a6b345b4fc2cb5f29b70589.15e4b80e0db9ddfa092bb2a03d56050575455bb50729e3c68617a4aa2f7025ec\n",
      "2021-07-15 12:14:13,219 Ignore 1 sentence(s) with no tokens.\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "sentences = splitter.split(text2)\n",
    "tagger = SequenceTagger.load('upos')\n",
    "tagger.predict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "pRroLb55SLDP"
   },
   "outputs": [],
   "source": [
    "flair_eng = []\n",
    "for sentence in sentences:\n",
    "    list_of_tags = sentence.to_tagged_string().split()\n",
    "    for word in list_of_tags:\n",
    "      if '<' in word and word != '<PUNCT>':\n",
    "        word = re.sub('<|>', '', word)\n",
    "        flair_eng.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhuTCxMIDAVP"
   },
   "source": [
    "###### Тут я посмотрю что нашли мои парсеры и приведу к единой системе. За основу ляжет flair. Поскольку англ делался через колаб, некоторые аутпуты могут быть пустыми, но ничего важного в них нет, просто удобство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fV_djLhDSLDT",
    "outputId": "38ef37d4-a8b5-4e2a-efba-dbef4f444672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 25, 'VERB': 18, 'DET': 17, 'ADP': 14, 'PRON': 12, 'ADJ': 9, 'PROPN': 1, 'PART': 1, 'AUX': 1, 'ADV': 1, 'NUM': 1})\n"
     ]
    }
   ],
   "source": [
    "p = Counter(flair_eng)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XAfIEZbbrrsY",
    "outputId": "963beb0a-f7d1-480a-a153-57c1c9a34a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 25, 'DET': 18, 'VERB': 13, 'ADP': 12, 'PRON': 11, 'ADJ': 9, 'AUX': 6, 'SCONJ': 2, 'PROPN': 1, 'PART': 1, 'ADV': 1, 'NUM': 1})\n"
     ]
    }
   ],
   "source": [
    "o = Counter(spacy_eng)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eAnYlag0zqQp",
    "outputId": "f45951d7-c325-49fa-dfe6-27861b940c9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NN': 26, 'DT': 17, 'IN': 11, 'VBD': 10, 'JJ': 6, 'PRP': 6, 'VBZ': 5, 'TO': 4, 'PRP$': 3, 'NNS': 3, 'VBN': 2, 'VB': 2, 'MD': 1, 'EX': 1, 'RB': 1, 'WDT': 1, 'CD': 1})\n"
     ]
    }
   ],
   "source": [
    "q = Counter(nltk_eng)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk\n",
    "\"NN\" == \"NOUN\" <br>\n",
    "\"DT\" == \"DET\"<br>\n",
    "##### тут не очень понятно что делать, потому что нлтк размечает и предлоги, и союзы как in. Поэтому будет все adposition<p>\n",
    "\"IN\" == \"ADP\"<br>\n",
    "\"VBD\" == \"VERB\"<br>\n",
    "\"JJ\" == \"ADJ\"<br>\n",
    "\"PRP\" == \"PRON\"<br>\n",
    "\"VBZ\" == \"VERB\"<br>\n",
    "\"NNS\" == \"NOUN\"<br>\n",
    "##### тут тоже непонятно, потому что другие парсеры делят to на adposition and particle. Но большинство случаев adp<p>\n",
    "\"TO\" == \"ADP\"<br>\n",
    "\"PRP$\" == \"PRON\"<br>\n",
    "\"VBN\" == \"VERB\"<br>\n",
    "\"VB\" == \"VERB\"<br>\n",
    "\"MD\" == \"VERB\"<br>\n",
    "\"EX\" == \"PRON\"<br>\n",
    "\"RB\" == \"ADV\"<br>\n",
    "\"EX\" == \"PRON\"<br>\n",
    "\"WDT\" == \"DET\"<br>\n",
    "\"CD\" == \"NUM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "zXrgchfX8WMC"
   },
   "outputs": [],
   "source": [
    "nltk_st = []\n",
    "for tag in nltk_eng:\n",
    "  if tag == 'NN':\n",
    "    tag = re.sub('NN', 'NOUN', tag)\n",
    "\n",
    "  elif tag == 'DT':\n",
    "    tag = re.sub('DT', 'DET', tag)\n",
    "\n",
    "  elif tag == 'IN':\n",
    "    tag = re.sub('IN', 'ADP', tag)\n",
    "\n",
    "  elif tag == 'VBD':\n",
    "    tag = re.sub('VBD', 'VERB', tag)\n",
    "\n",
    "  elif tag == 'JJ':\n",
    "    tag = re.sub('JJ', 'ADJ', tag)\n",
    "\n",
    "  elif tag == 'PRP':\n",
    "    tag = re.sub('PRP', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'VBZ':\n",
    "    tag = re.sub('VBZ', 'VERB', tag)\n",
    "\n",
    "  elif tag == 'NNS':\n",
    "    tag = re.sub('NNS', 'NOUN', tag)\n",
    "\n",
    "  elif tag == 'TO':\n",
    "    tag = re.sub('TO', 'ADP', tag)\n",
    "\n",
    "  elif tag == 'PRP$':\n",
    "    tag = re.sub(r'PRP.+', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'VBN':\n",
    "    tag = re.sub('VBN', 'VERB', tag)\n",
    "  \n",
    "  elif tag == 'VB':\n",
    "    tag = re.sub('VB', 'VERB', tag)\n",
    "  \n",
    "  elif tag == 'MD':\n",
    "    tag = re.sub('MD', 'VERB', tag)\n",
    "\n",
    "  elif tag == 'EX':\n",
    "    tag = re.sub('EX', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'RB':\n",
    "    tag = re.sub('RB', 'ADV', tag)\n",
    "\n",
    "  elif tag == 'EX':\n",
    "    tag = re.sub('EX', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'WDT':\n",
    "    tag = re.sub('WDT', 'DET', tag)\n",
    " \n",
    "  elif tag == 'CD':\n",
    "    tag = re.sub('CD', 'NUM', tag)\n",
    "  nltk_st.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "CoDu3Dzs8WKH",
    "outputId": "886074e2-17e5-4745-b59e-3f8d89ae0c32"
   },
   "source": [
    "И считаем accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "id": "TZoGekEb4kjq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\trekc\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\trekc\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "TlmJCIK54leg",
    "outputId": "353a73dc-29f2-4ab8-ef42-d10c8496f569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy accuracy: 0.94\n",
      "Flair accuracy: 0.94\n",
      "NLTK accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Spacy accuracy: ' + str(accuracy_score(spacy_eng, gold2)))\n",
    "print('Flair accuracy: ' + str(accuracy_score(flair_eng, gold2)))\n",
    "print('NLTK accuracy: ' + str(accuracy_score(nltk_st, gold2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJJmWeb-SLDV"
   },
   "source": [
    "### MYSTEM\n",
    "Чтобы быстрее работало"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ohPQQA28SLDW"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "lemmas = m.analyze(text1)\n",
    "mystem_ru = []\n",
    "for word in lemmas:\n",
    "    if 'analysis' in word:\n",
    "        gr = word['analysis'][0]['gr']\n",
    "        pos = gr.split('=')[0].split(',')[0]\n",
    "        mystem_ru.append(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foyDagMzSLDY"
   },
   "source": [
    "### PYMORHPY\n",
    "Можно учесть вероятности разборов определенной части речи, или посмотреть не попал ли какой-то разбор в верное, но я не буду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "1kwz6nDySLDZ"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "pymorphy_ru = []\n",
    "words = [w.lower() for w in word_tokenize(text1) if w.isalpha()]\n",
    "for word in words:\n",
    "    x = morph.parse(word)\n",
    "    POS = x[0].tag.POS\n",
    "    pymorphy_ru.append(POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaA3SsaTSLDb"
   },
   "source": [
    "### NATASHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "KMgS4S8uSLDb"
   },
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "fkjg_GuoSLDd"
   },
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "_V_pP7rnSLDf"
   },
   "outputs": [],
   "source": [
    "doc = Doc(text1)\n",
    "doc.segment(segmenter)\n",
    "natasha_ru = []\n",
    "doc.tag_morph(morph_tagger)\n",
    "for token in doc.tokens:\n",
    "    if token.pos != 'PUNCT':\n",
    "        natasha_ru.append(token.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SesOFbQ-SLDh"
   },
   "source": [
    "###### Приводим все к одному"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78bGdPpMSLDj"
   },
   "source": [
    "###### natasha - standart <p>\n",
    "###### mystem -> natasha <p>\n",
    "'V' = 'VERB' <p>\n",
    "'S' = 'NOUN' <p>\n",
    "'PR' = 'PREP'<p>\n",
    "'A' = 'ADJ'<p>\n",
    "'APRO' = 'PRON'<p>\n",
    "'ADVPRO' = 'ADV' #местоименное наречие привожу к обычному<p>\n",
    "'SPRO' = 'PRON'<p>\n",
    "\n",
    "###### natasha -> mystem <p>\n",
    "# тут нельзя разделить адпозишн на частицу и предлог, но чаще это предлоги, так что буду считать их<p>\n",
    "'ADP' = 'PREP'<p>\n",
    "'SCONJ' = 'CONJ'<p>\n",
    "'CCONJ' = 'CONJ'<p>\n",
    "\n",
    "##### pymorhpy -> natasha<p>\n",
    "'ADVB' = 'ADV'<p>\n",
    "'ADJF' = 'ADJ'<p>\n",
    "'NPRO' = 'PRON'<p>\n",
    "'PRCL' = 'PART'<p>\n",
    "'COMP' = 'ADJ' # сравнение может быть как прил, так и наречием, но прилагательные чаще<p>\n",
    "'NUMR' = 'NUM'<p>\n",
    "'INFN' = 'VERB'<p>\n",
    "###### причастия я не трогаю, потому что они не встретились<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_st = []\n",
    "for tag in mystem_ru:\n",
    "  if tag == 'V':\n",
    "    tag = re.sub('V', 'VERB', tag)\n",
    "\n",
    "  elif tag == 'S':\n",
    "    tag = re.sub('S', 'NOUN', tag)\n",
    "\n",
    "  elif tag == 'PR':\n",
    "    tag = re.sub('PR', 'PREP', tag)\n",
    "    \n",
    "  elif tag == 'A':\n",
    "    tag = re.sub('A', 'ADJ', tag)\n",
    "    \n",
    "  elif tag == 'APRO':\n",
    "    tag = re.sub('APRO', 'PRON', tag)\n",
    "    \n",
    "  elif tag == 'ADVPRO':\n",
    "    tag = re.sub('ADVPRO', 'ADV', tag)\n",
    "    \n",
    "  elif tag == 'SPRO':\n",
    "    tag = re.sub('SPRO', 'PRON', tag)\n",
    "    \n",
    "  mystem_st.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "xwlIi2hJSLDt"
   },
   "outputs": [],
   "source": [
    "natasha_st = []\n",
    "for tag in natasha_ru:\n",
    "  if tag == 'ADP':\n",
    "    tag = re.sub('ADP', 'PREP', tag)\n",
    "\n",
    "  elif tag == 'SCONJ':\n",
    "    tag = re.sub('SCONJ', 'CONJ', tag)\n",
    "\n",
    "  elif tag == 'CCONJ':\n",
    "    tag = re.sub('CCONJ', 'CONJ', tag)\n",
    "  \n",
    "  natasha_st.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "fUtqwlF0SLDm"
   },
   "outputs": [],
   "source": [
    "pymorhpy_st = []\n",
    "for tag in pymorphy_ru:\n",
    "  if tag == 'ADVB':\n",
    "    tag = re.sub('ADVB', 'ADV', tag)\n",
    "\n",
    "  elif tag == 'PRTF':\n",
    "    tag = re.sub('PRTF', 'VERB', tag)\n",
    "\n",
    "  elif tag == 'PRTS':\n",
    "    tag = re.sub('PRTS', 'VERB', tag)\n",
    "    \n",
    "  elif tag == 'ADJF':\n",
    "    tag = re.sub('ADJF', 'ADJ', tag)\n",
    "\n",
    "  elif tag == 'NPRO':\n",
    "    tag = re.sub('NPRO', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'PRCL':\n",
    "    tag = re.sub('PRCL', 'PART', tag)\n",
    "\n",
    "  elif tag == 'NPRO':\n",
    "    tag = re.sub('NPRO', 'PRON', tag)\n",
    "\n",
    "  elif tag == 'COMP':\n",
    "    tag = re.sub('COMP', 'ADJ', tag)\n",
    "\n",
    "  elif tag == 'NUMR':\n",
    "    tag = re.sub('NUMR', 'NUM', tag)\n",
    "\n",
    "  elif tag == 'INFN':\n",
    "    tag = re.sub('INFN', 'VERB', tag)\n",
    "    \n",
    "  pymorhpy_st.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считает accuracy для русского, майстем победил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Pn5FHRYOSLDq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mystem accuracy: 0.9\n",
      "Natasha accuracy: 0.85\n",
      "Pymorphy accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Mystem accuracy: ' + str(accuracy_score(mystem_st, gold1)))\n",
    "print('Natasha accuracy: ' + str(accuracy_score(natasha_st, gold1)))\n",
    "print('Pymorphy accuracy: ' + str(accuracy_score(pymorhpy_st, gold1)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
